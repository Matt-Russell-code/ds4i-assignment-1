<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>DS4I - Project Writeup</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="DS4i_writeup_files/libs/clipboard/clipboard.min.js"></script>
<script src="DS4i_writeup_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="DS4i_writeup_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="DS4i_writeup_files/libs/quarto-html/popper.min.js"></script>
<script src="DS4i_writeup_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="DS4i_writeup_files/libs/quarto-html/anchor.min.js"></script>
<link href="DS4i_writeup_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="DS4i_writeup_files/libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="DS4i_writeup_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="DS4i_writeup_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="DS4i_writeup_files/libs/bootstrap/bootstrap-bb462d781dde1847d9e3ccf7736099dd.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="DS4i_writeup_files/libs/kePrint-0.0.1/kePrint.js"></script>

<link href="DS4i_writeup_files/libs/lightable-0.0.1/lightable.css" rel="stylesheet">

<link href="DS4i_writeup_files/libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">

<script src="DS4i_writeup_files/libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>

<link href="DS4i_writeup_files/libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet">

<script src="DS4i_writeup_files/libs/datatables-binding-0.33/datatables.js"></script>

<script src="DS4i_writeup_files/libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>

<link href="DS4i_writeup_files/libs/dt-core-1.13.6/css/jquery.dataTables.min.css" rel="stylesheet">

<link href="DS4i_writeup_files/libs/dt-core-1.13.6/css/jquery.dataTables.extra.css" rel="stylesheet">

<script src="DS4i_writeup_files/libs/dt-core-1.13.6/js/jquery.dataTables.min.js"></script>

<link href="DS4i_writeup_files/libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet">

<script src="DS4i_writeup_files/libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>



</head>

<body class="fullcontent quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">DS4I - Project Writeup</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="av.jpg" class="img-fluid figure-img" width="2000"></p>
</figure>
</div>
</div>
</div>
<p><span style="font-size:12px">Photo by Nicolas Cool on Unsplash</span></p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
</section>
<section id="literature-review" class="level2">
<h2 class="anchored" data-anchor-id="literature-review">Literature Review</h2>
<p>Snow avalanches are a recognised hazard in snow-prone mountain regions worldwide. Unlike in many alpine regions, avalanches in Scotland rarely impact large settlements and infrastructure, however, pose significant risk to recreational users in the Scottish Highlands (Diggins, 2009; Ward, 1980). Winter activities, such as climbing, walking, and skiing are increasingly popular, leading to greater human exposure to avalanche-prone terrain and resulting in numerous injuries and occasional fatalities each year (Scottish Avalanche Information Service [SAIS], 2024). This has prompted several studies to examine Scottish snowpack conditions and avalanche forecasting strategies, with the earliest studies conducted between 1970 and 1980 (Langmuir, 1970; Spink, 1970; Beattie, 1976; Ward, 1980; Ward &amp; Beattie, 1985). However, these early studies were largely descriptive, relying on snow-pit measurements and expert judgements to identify snow properties and weather conditions correlated with avalanche risk. Building on this foundation, Ward (1984) applied one of the first predictive forecasting models for avalanches in Scotland.</p>
<p>Numerous studies emphasise the inherent complexity of avalanche modelling where predictions are based on multiple interacting factors (Choubin et al., 2019; Herwijen et al., 2016; Hendrick et al., 2023; Pozdnoukhov et al., 2008; Singh &amp; Ganju, 2008). This complexity is only heightened in regions with highly variable weather patterns (Sharma &amp; Ganju, 1999). In response, early statistical methods such as nearest neighbours became a popular technique to support (not replace) forecasters in predicting avalanche outcomes through relating current weather conditions to past avalanche events (Blagovechshenskiy et al., 2023; Kala et al., 2025; Pozdnoukhov et al., 2018; Singh &amp; Ganju, 2008). However, this approach is susceptible to overfitting and struggles with complex and high-dimensional data (Kala et al., 2025; Pozdnoukhov et al., 2018; Singh &amp; Ganju, 2018). Using a dataset from Lochaber, Scotland, Pozdnoukhov et al.&nbsp;(2008) reported that support vector machines (SVMs) showed a broadly similar performance to a baseline nearest neighbours method, however, had the added advantage of handling high dimensionality datasets and produced more descriptive forecasts. SVMs have been explored and shown success in aiding avalanche risk forecasting in other regions including Iran, India, Switzerland, and Tibet (Choubin et al., 2019; Rahmati et al., 2019; Schirmer et al., 2009; Tiwari et al., 2021; Wen et al., 2022).&nbsp;</p>
<p>Over recent years, more complex machine learning (ML) algorithms such as regression trees, random forests, and neural networks have demonstrated strong predictive performance in avalanche forecasting (Blagovechshenskiy et al., 2023; Choubin et al., 2019; Gauthier et al., 2025; Hendrick et al., 2023; Rahmati et al., 2019; Singh &amp; Ganju, 2018; Tiwari et al., 2021; Wen et al., 2022). Avalanche datasets are often high-dimensional, and using human forecaster judgement to select which features to include can be highly subjective and variable (Helbig et al., 2015; Pozdnoukhov et al., 2008). Hybrid approaches, which combine ML with expert-guided feature selection, have shown practical value (Gauthier et al., 2025). However, fully data-driven forecasting methods, particularly neural networks, offer important advantages.</p>
<p>Simulating the work of a human brain, neural networks are deep learning algorithms consisting of interconnected nodes/neurons that can model complex and nonlinear relationships between inputs and outputs (Blagovechshenskiy et al., 2023; Sharma et al., 2023; Tu, 1996). Their ability to process all input variables simultaneously allows them to implicitly learn interactions and patterns in the data without prior knowledge on which variables are most important (Blagovechshenskiy et al., 2023; Fromm &amp; Schonberger, 2022; Sharma et al., 2023). Studies in avalanche forecasting from regions such as Switzerland, Kazakhstan, and&nbsp; India have demonstrated that neural networks not only achieve strong predictive performance, but can also assess the relative importance of each variable to avalanche risk (Fromm &amp; Schonberger; Sharma et al., 2023; Singh &amp; Ganju, 2008). This ability makes them particularly well suited for high-dimensional datasets, such as those encountered in avalanche forecasting, as well as in contexts where prior domain knowledge is limited or when the most relevant predictors are unknown.</p>
<p>Despite advances in data-driven avalanche forecasting worldwide, research specific to Scotland remains limited. This scarcity lies in three domains:&nbsp;</p>
<p>(1) The small number of published forecasting studies (only 9 relevant peer-reviewed papers exist on Scopus, with the most recent study conducted in 2011 (keywords: ( “avalanche forecasting” OR “avalanche prediction” ) AND Scotland)</p>
<p>(2) The restricted range of statistical approaches explored (only KNN and SVM) (Joachim et al., 2004; Pozdnoukhov et al., 2008; Pozdnoukhov et al., 2011; Purves et al., 2003)</p>
<p>(3) The focus on only a few regions in Scotland (primarily the Cairngorms and Lochaber regions)</p>
<p>This limited research interest likely stems from the highly localised nature of avalanche risk in Scotland, which generally occurs in remote areas and impacts only a small subset of individuals (Diggins, 2009; SAIS, 2024). Nevertheless, improved avalanche forecasting is argued to be increasingly important under changing climate conditions and global warming, which may alter snowpack properties and avalanche risk and frequency (Gauthier et al., 2025; Werritty &amp; Sugden, 2013). A detailed discussion of climate change, however, is beyond the scope of this paper. As such, the present study aims to extend forecasting research in Scotland both spatially and methodologically by applying a neural network (or two or three?????) across the six distinct regions of Creah Meagaidh, Glencoe, Lochaber, Northern Cairngorms, Southern Cairngorms, and Torridon.</p>
<p>&lt;insert paragraph explaining modelling approaches of prev papers + this project’s modelling approaches. I.e. the neural net architecture&gt;</p>
<p>Hypothesis???? We can workshop together</p>
</section>
<section id="context-and-dataset" class="level2">
<h2 class="anchored" data-anchor-id="context-and-dataset">Context and Dataset</h2>
<p>Scotland experiences a mild, wet, and temperate maritime climate due to the strong influence of the North Atlantic Ocean and persistent south-westerly winds (Pozdnoukhov et al., 2008; Scottish Government, 2011). These conditions result in rapid temperature changes, frequent heavy precipitation (falling as either snow or rain in the winter), and strong winds. With the highest peak, Ben Nevis in Lochaber (1345 m), mountains are low compared to alpine ranges (~ 4000 m), resulting in a snowpack that is typically shallower, wetter, and more variable in comparison (Britannica, 2025; Pozdnoukhov et al., 2008; WSL Institute for Snow and Avalanche Research SLF, 2016). Aspects such as rapid freeze-thaw cycles, rain-on-snow, and wind redistribution further destabilise snow structure and stability, creating avalanche risks that can arise and disappear within a short time (Diggins, 2009; Pozdnoukhov et al., 2008; Purves et al., 2003; Scottish Government, 2011). Snowpack conditions also differ regionally; while the West is characterised as strongly maritime, with mild and wet winters, the North and East experience colder and drier conditions (MetOffice, 2010). As such, Scotland’s climate is highly variable both spatially and temporally, adding to the complexity of predicting avalanche risk.</p>
<p>This paper uses a 15-year archive of avalanche forecasts from Scotland across the six areas of Creah Meagaidh, Glencoe, Lochaber, Northern Cairngorms, Southern Cairngorms, and Torridon, produced by the Scottish Avalanche Information Service (2025). Figure ? illustrates the spatial distribution of avalanche observations over this time frame, with points marking individual events and labels indicating the locations of these six areas. The overall total observations by area and hazard category (Table ?) reflects the difference in observation frequency rather than absolute avalanche activity: Cairngorms (Northern and Southern) and Lochaber, located in the colder and drier North and East, have the most recorded observations, whereas Torridon in the maritime West has substantially fewer. Across all areas, Low and Moderate hazard levels are the most frequently recorded, while High hazard events are comparatively rare and concentrated primarily in Northern Cairngorms and Lochaber.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="DS4i_writeup_files/figure-html/map-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption></caption>
<colgroup>
<col style="width: 27%">
<col style="width: 5%">
<col style="width: 12%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 6%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Area</th>
<th style="text-align: right;">Low</th>
<th style="text-align: right;">Moderate</th>
<th style="text-align: right;">Considerable -</th>
<th style="text-align: right;">Considerable +</th>
<th style="text-align: right;">High</th>
<th style="text-align: right;">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Creag Meagaidh</td>
<td style="text-align: right;">636</td>
<td style="text-align: right;">545</td>
<td style="text-align: right;">413</td>
<td style="text-align: right;">155</td>
<td style="text-align: right;">63</td>
<td style="text-align: right;">1812</td>
</tr>
<tr class="even">
<td style="text-align: left;">Glencoe</td>
<td style="text-align: right;">716</td>
<td style="text-align: right;">524</td>
<td style="text-align: right;">405</td>
<td style="text-align: right;">109</td>
<td style="text-align: right;">58</td>
<td style="text-align: right;">1812</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Lochaber</td>
<td style="text-align: right;">597</td>
<td style="text-align: right;">498</td>
<td style="text-align: right;">506</td>
<td style="text-align: right;">116</td>
<td style="text-align: right;">56</td>
<td style="text-align: right;">1773</td>
</tr>
<tr class="even">
<td style="text-align: left;">Northern Cairngorms</td>
<td style="text-align: right;">655</td>
<td style="text-align: right;">567</td>
<td style="text-align: right;">501</td>
<td style="text-align: right;">122</td>
<td style="text-align: right;">46</td>
<td style="text-align: right;">1891</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Southern Cairngorms</td>
<td style="text-align: right;">751</td>
<td style="text-align: right;">546</td>
<td style="text-align: right;">383</td>
<td style="text-align: right;">72</td>
<td style="text-align: right;">35</td>
<td style="text-align: right;">1787</td>
</tr>
<tr class="even">
<td style="text-align: left;">Torridon</td>
<td style="text-align: right;">678</td>
<td style="text-align: right;">373</td>
<td style="text-align: right;">85</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1143</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Data cover the Scottish winters (November to April) from the December 2009 to March 2025. Predictor variables are categorised into three main groups, including (1) position and topography, (2) weather, and (3) snowpack test, all collected at the forecast location. Each observation also includes the date and the forecast area (metadata). For an overview of the predictors available, see Table ? below.</p>
<div class="cell">
<div class="cell-output-display">
<table class="table caption-top table-sm table-striped small" data-quarto-postprocess="true">
<caption>\emph{Overview of predictor variables available in the avalanche forecast dataset.}</caption>
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">Predictor_Group</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Variables</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left; width: 8em;">Metadata</td>
<td style="text-align: left; width: 30em;">date, area</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 8em;">Position and Topography</td>
<td style="text-align: left; width: 30em;">longitude, latitude, altitude, aspect of slope, incline of slope</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 8em;">Weather</td>
<td style="text-align: left; width: 30em;">air temperature, wind direction, wind speed, cloud cover, precipitation code, snowdrift, total snow depth, foot penetration, ski penetration, rain observed at 900m elevation, summit air temperature, summit wind direction, summit wind speed</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 8em;">Snowpack Test</td>
<td style="text-align: left; width: 30em;">max. temperature gradient, max. hardness gradient, no.settle, snow.index, insolation, crystals, wetness, AV.Cat, and snow temperature</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="exploratory-data-analysis" class="level2">
<h2 class="anchored" data-anchor-id="exploratory-data-analysis">Exploratory Data Analysis</h2>
<section id="a.-feature-map-correlations" class="level3">
<h3 class="anchored" data-anchor-id="a.-feature-map-correlations">a. Feature Map Correlations</h3>
<p>The Scottish avalanche dataset contains several features that are moderately to strongly correlated, while others appear largely independent (Figure ?). This pattern suggests a potential redundancy. From a modelling perspective, highly correlated features can increase complexity and obscure unique contributors, however, can also capture the multifactorial nature of avalanche risk. In the context of neural networks, the presence of correlated variables is not inherently problematic, since the model can learn non-linear interactions. However, strong correlations can increase the risk of overfitting if the network memorises patterns rather than generalising to new data.</p>
<p>The highest correlation found was between summit air temperature and air temperature (r = 0.8463287), indicating strong redundancy. Nevertheless, both variables were retained as each likely capture a different aspect relevant to forecasting (i.e., summit conditions versus broader conditions). Air temperature is an identified key driver of avalanche conditions and is expected to be an important predictor in the final neural network (Fromm &amp; Schonberger, 2022; Gauthier et al., 2025; Pozdnoukhouv et al., 2018; Souckova et al., 2022; Ward,1980). Exploration of air temperature across observed avalanche hazard (OAH) levels further supports its importance in forecasting (Figure ?). Higher hazard categories are generally associated with lower air temperatures, with “Considerable -”, “Considerable +”, and “High” hazards centred below 0 °C. “Low” hazard days show medians above freezing and wider variability. The transition at “Moderate” hazard, where temperatures cluster around 0 °C, reflects conditions that can either stabilise or destabilise the snowpack through freeze-thaw cycles. These patterns highlight Scotland’s sensitivity to rapid temperature shifts and their impact on avalanche activity (Diggins, 2009; Pozdnoukhov et al., 2008).</p>
<p>Other correlations with 0.5&lt;|r|&lt; 0.80 are moderately strong but remain informative and manageable, as neural networks can accommodate interdependent inputs.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="DS4i_writeup_files/figure-html/correlation-plot-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="DS4i_writeup_files/figure-html/temperature-plot-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="b.-precipitation-type" class="level3">
<h3 class="anchored" data-anchor-id="b.-precipitation-type">b. Precipitation Type</h3>
<p>The distribution of OAH levels varies clearly across different precipitation types (Figure ?). Low hazard predominates under conditions of none (0) or trace (2) precipitation, whereas higher hazard categories become increasingly prevalent as snowfall intensity increases. Heavy snow (level 10) is associated with a substantially larger share of “Considerable” and “High” hazard ratings (81.8965517 %). This aligns with existing knowledge of the Scottish climate, where rapid weather shifts and frequent rain or snow-on-snow events contribute to unstable snowpack conditions (Pozdnoukhov et al., 2008; Purves et al., 2003).</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="DS4i_writeup_files/figure-html/precip-plot-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="c.-seasonality" class="level3">
<h3 class="anchored" data-anchor-id="c.-seasonality">c.&nbsp;Seasonality</h3>
<p>Monthly patterns of OAH across the extended avalanche season (November to May) reveal clear seasonal trends (Figure ?). Early (November-December) and late (April-May) months are dominated by low and moderate hazards, while mid-season months (Jan-Mar) contain a higher proportion of considerable and high hazards. Most forecasts occur between December and March, highlighting the period of greatest avalanche risk (SAIS, 2024). These patterns reflect the cyclical nature of snowpack development, with mid-winter weather instability driving higher-risk avalanches (Diggins, 2009; Podzdnoukhov et al., 2008; Purves et al., 2003). For modelling, this seasonality indicates that hazard levels are unevenly distributed, however, neural networks can accommodate complex, changing relationships between weather conditions and other important variables.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="DS4i_writeup_files/figure-html/season-plots-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="d.-fah-vs-oah" class="level3">
<h3 class="anchored" data-anchor-id="d.-fah-vs-oah">d.&nbsp;FAH vs OAH</h3>
<p>Lastly, Figure 6 shows the relationship between forecast avalanche hazard (FAH) on day <em>t</em> and observed avalanche hazard (OAH) on day <em>t+1</em>. Each column sums to 100%, showing how outcomes were distributed given a specific forecast level. Forecasts of “Low” hazard were highly accurate, with 86.5089121 % of cases confirmed the following day. This indicates that forecasters were most successful in predicting stable snowpack conditions and low hazard scenarios.</p>
<p>For intermediate levels such as “Moderate” and “Considerable –” the agreement weakens. Only about half of “Moderate” forecasts matched the following day’s observations, with a substantial spillover into “Low” and “Considerable –”. “Considerable –” forecasts split almost evenly between being observed as “Moderate,” “Considerable –,” and “Considerable +.” This pattern shows that there is a challenge in differentiating between neighbouring hazard categories, which may highlight the subjectivity and sensitivity of these intermediate hazard thresholds.</p>
<p>Forecasts of “High” hazard showed weaker reliability. Fewer than one-quarter of these forecasts corresponded to an observed “High” hazard the next day. Most “High” forecasts aligned with “Considerable –” or “Considerable +” outcomes. This shows that there is a tendency towards over-prediction of extreme conditions, or difficulty in anticipating when weather and snowpack instabilities will escalate into truly high-risk scenarios.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="DS4i_writeup_files/figure-html/OAH-FAH-plot-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The plot shows that the forecast (FAH) is highest in stable, low-risk conditions and lowest at the extremes, with the middle categories marked by uncertainty. This implies that avalanche hazard ratings are best treated as ordinal outcomes for modelling purposes, where the cost of misclassification is not uniform and depends on how far apart the categories are. Neural networks can capture these patterns well when framed as ordinal classfiers. They can learn that misclassifications most often occur between neighbouring hazard levels, instead of treating all errors equally. Class imbalances will also need to be addressed during model training to ensure the network does not simply default to predicting the most common outcomes.</p>
</section>
<section id="e.-missing-values" class="level3">
<h3 class="anchored" data-anchor-id="e.-missing-values">e. Missing Values</h3>
</section>
</section>
<section id="data-cleaning-and-feature-engineering" class="level2">
<h2 class="anchored" data-anchor-id="data-cleaning-and-feature-engineering">Data Cleaning and Feature Engineering</h2>
<p>Feature engineering mainly consisted of constructing temporal variables for the models. In particular, a feed forward neural network does not natively capture any time series trends. Given that the above exploratory analysis highlights that observed avalanche risk varies according to the season, and time of year, several variable were constructed to take this into account.</p>
<p><br></p>
<p>Firstly, before removing any observations that contained large amount of missing values, we constructed constructed several variable marking the samples time of day, day of the week, month and year from the date. Next, we created a variable to represent the subsequent seasons in the data, as we observed a trend that avalanche risk appeared to be increasing year on year. The first season of avalanche recordings begins in December in 2009 and ends in April. We constructed a categorical variable to represent each season from 2009 to 2025 beginning from December into the following year.</p>
<div class="cell">
<div class="cell-output-display">
<table class="table table-hover caption-top table-sm table-striped small" data-quarto-postprocess="true">
<caption>Missing Value Exploration</caption>
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">Variable</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Missing (%)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">AV.Cat</td>
<td style="text-align: right;">23.3494</td>
</tr>
<tr class="even">
<td style="text-align: left;">Ski.Pen</td>
<td style="text-align: right;">22.4898</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Summit.Wind.Dir</td>
<td style="text-align: right;">12.3548</td>
</tr>
<tr class="even">
<td style="text-align: left;">Crystals</td>
<td style="text-align: right;">9.2566</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Summit.Wind.Speed</td>
<td style="text-align: right;">8.5293</td>
</tr>
<tr class="even">
<td style="text-align: left;">Summit.Air.Temp</td>
<td style="text-align: right;">7.0653</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Snow.Index</td>
<td style="text-align: right;">6.9991</td>
</tr>
<tr class="even">
<td style="text-align: left;">Max.Temp.Grad</td>
<td style="text-align: right;">6.1679</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Max.Hardness.Grad</td>
<td style="text-align: right;">5.4029</td>
</tr>
<tr class="even">
<td style="text-align: left;">Wetness</td>
<td style="text-align: right;">5.3273</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Insolation</td>
<td style="text-align: right;">4.7606</td>
</tr>
<tr class="even">
<td style="text-align: left;">Snow.Temp</td>
<td style="text-align: right;">3.7404</td>
</tr>
<tr class="odd">
<td style="text-align: left;">OAH</td>
<td style="text-align: right;">3.4854</td>
</tr>
<tr class="even">
<td style="text-align: left;">Aspect</td>
<td style="text-align: right;">3.0320</td>
</tr>
<tr class="odd">
<td style="text-align: left;">No.Settle</td>
<td style="text-align: right;">2.7298</td>
</tr>
<tr class="even">
<td style="text-align: left;">Total.Snow.Depth</td>
<td style="text-align: right;">1.4168</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Wind.Dir</td>
<td style="text-align: right;">1.3696</td>
</tr>
<tr class="even">
<td style="text-align: left;">Wind.Speed</td>
<td style="text-align: right;">0.3967</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Foot.Pen</td>
<td style="text-align: right;">0.2739</td>
</tr>
<tr class="even">
<td style="text-align: left;">Incline</td>
<td style="text-align: right;">0.2172</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Air.Temp</td>
<td style="text-align: right;">0.2172</td>
</tr>
<tr class="even">
<td style="text-align: left;">Cloud</td>
<td style="text-align: right;">0.1700</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Alt</td>
<td style="text-align: right;">0.0472</td>
</tr>
</tbody><tfoot>
<tr class="odd">
<td style="text-align: left; padding: 0;"><span style="font-style: italic;">Note: </span></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left; padding: 0;"><sup></sup> All values rounded to 4 decimal places.</td>
<td style="text-align: right;"></td>
</tr>
</tfoot>

</table>
</div>
</div>
<p>Missing values were also a challenge. Table ? presents the percentage of missing values for each feature in the data that had misisng values. <em>Av.Cat</em> was the first variable we felt should be eliminated. We could not find what this variable represented, and it had implausible values ( For example : NA, 3, -2, 2, 1, 4, 8800, -1, 0, 1021, 4400, -9999, 99, 88, 44, 5031, 121 ). Shown in Figure ? below, we observed no discernible trend in the relationship between Ski penetration and OAH, save for High risk avalanches. Overall, we removed this feature, as the contribution of snow precipitation to the risk would likely be well represented by other variables in the data. Lastly, we removed Summit wind direction as well, (roughly 12% missing). Similarly, to <em>Ski.pen</em>, we notice no discernible trend, and decided to drop this feature as well.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="DS4i_writeup_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Lastly, we also dropped categorical variables that had very high cardinality, which included <em>OsGrid</em> and <em>Location</em>. <em>Osgrid</em> appeared to be some kind of ID variable with over 3000 unique values. When one hot encoding this would make our data set unnecessarily complex, and we surmised that this variable likely would not be indicative of risk. Likewise, we also dropped Location for similar reasoning. We had the latitiude and longitude of included in the data as well as the <em>Area</em> indicative which we expected to be more indicative of avalanche risk, so we dropped this feature as well to reduce unnecessary complexity.</p>
<p>Having dropped the above variables, we were left with roughly 35 % non-complete samples in the data. We dropped the remaining samples that contained missing values to maintain complete cases for the models. Ideally, it would be better to maintain more observations. However, we felt we still had a large enough sample to maintain representative results (around 7000 observations). At a later stage, we fit our best performing model to a simply imputed data set and achieve an accuracy roughly equivalent to the complete cases data set.</p>
<section id="modeling-methodology" class="level3">
<h3 class="anchored" data-anchor-id="modeling-methodology">Modeling Methodology</h3>
<p>There are three main models used in this project. Firstly, a feed forward neural network (FFN), a convolutional neural network (CNN) and a recurrent neural network (RNN). The idea behind the feed forward neural network is that it would likely leverage the categorical variables, like forecasted avalanche risk, well in predicting the target. However, CNN and RNN were more likely to leverage any time series trends present in the data.</p>
<p>A feed forward neural network makes use of a series of nodes. The basic structure of neural networks is first input nodes, variable layers of perceptron nodes and output nodes. The perceptron nodes (or hidden layers) contain activation functions and weights. The first hidden layer nodes take the weighted sum of the input layer, apply the activation function to this input and multiply that by the weight. Subsequent layers take the previous layers calculations as input. The weights determine the amount of influence that part of the system has on the algorithm, while the activation functions introduce non-linearity. To determine the weights, they are first randomly assigned, and then back propagation is completed during training with an optimizer like gradient descent to assign appropriate values.</p>
<p>Convolutional neural networks work differently, by sliding filters across the data which allow the algorithm to consider broader trends. The filter is essentially a matrix of weights, and the dot product between these weights and the data is calculated. These individual values are taken across the feature space, in turn highlighting any local patterns. Using multiple filters at once during training allows for the algorithm to learn various patterns simultaneously. After completing the above convolution, activation functions are applied to the resultant feature map to introduce non-linearity. Typically, a process called pooling is also applied, which reduces the dimensionality of the feature space, while preserving the most informative trends. One can stack numerous layers of convolutions to learn deeper trends in the data, although we found that 2 layers were a good balance between the model’s complexity and ability to generalize.</p>
<div class="cell">
<div class="cell-output-display">
<!-- VALID-padding convolution demo with filter display, static output values -->
<style>
  :root{ --cell:40px; --gap:6px; }
  .wrap{font-family:system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif; color:#111}
  .row{display:flex; gap:18px; align-items:flex-start}
  .col{flex:1}
  .label{font-size:13px; color:#444; margin: 4px 0 8px; font-weight:600}
  .board, .out{display:grid; gap:var(--gap); position:relative; padding:6px; border:1px solid #ddd; border-radius:12px; background:#fff}
  .board{grid-template-columns:repeat(5, var(--cell)); grid-auto-rows:var(--cell)}
  .out{grid-template-columns:repeat(3, var(--cell)); grid-auto-rows:var(--cell)}
  .cell, .ocell{display:flex; align-items:center; justify-content:center; font-weight:600; border:1px solid #ccc; border-radius:8px}
  .cell{background:#fff}
  .ocell{background:#f8fbff; border-color:#bcd7ff}
  .ocell.active{background:#e9f3ff}
  .hl{position:absolute; border:2px solid #0a84ff; border-radius:12px; box-shadow:0 0 0 3px rgba(10,132,255,.15) inset; pointer-events:none; transition:left .22s, top .22s}
  .controls{display:flex; gap:10px; align-items:center; padding:8px; border:1px solid #eee; border-radius:10px; background:#fafafa; margin:10px 0}
  .btn{padding:6px 10px; border:1px solid #bbb; border-radius:10px; background:#fff; cursor:pointer}
  .mini{font-size:12px; color:#555}
  .kernel{display:grid; grid-template-columns:repeat(3, var(--cell)); grid-auto-rows:var(--cell); gap:var(--gap); padding:6px; border:1px dashed #bbb; border-radius:10px; background:#fff; margin-top:10px}
  .kcell{display:flex; align-items:center; justify-content:center; font-weight:600; border:1px solid #ccc; border-radius:6px; background:#fdfdfd}
</style>

<div class="wrap">
  <div class="controls">
    <button class="btn" id="play">▶︎ Play</button>
    <button class="btn" id="pause" disabled="">⏸ Pause</button>
    <button class="btn" id="step">↦ Step</button>
    <label class="mini">Speed <input id="speed" type="range" min="200" max="1500" step="50" value="700"></label>
    <button class="btn" id="reset">↺ Reset</button>
  </div>

  <div class="row">
    <div class="col">
      <div class="label">Input feature map (5×5)</div>
      <div class="board" id="board"></div>
    </div>
    <div class="col">
      <div class="label">Dot‑product output (VALID, 3×3)</div>
      <div class="out" id="out"></div>
      <div class="mini">Position <span id="pos">(1,1)</span> • Value <span id="sum">—</span></div>
      <div class="label" style="margin-top:10px">Filter weights (3×3)</div>
      <div class="kernel" id="kernel"></div>
    </div>
  </div>
</div>

<script>
window.addEventListener('DOMContentLoaded', function(){
  const N = 5;
  const K = 3;
  const O = 3; // output 3x3

  const KERNEL = [
    [-1,-1,-1],
    [-1, 8,-1],
    [-1,-1,-1]
  ];

  // Preselected static output values (correct dot products precomputed)
  const STATIC_OUTPUT = [
    [0,  90, 100],
    [ 60, 200,  80],
    [ 70, 110,  95]
  ];

  const boardEl=document.getElementById('board');
  const outEl=document.getElementById('out');
  const posEl=document.getElementById('pos');
  const sumEl=document.getElementById('sum');
  const playBtn=document.getElementById('play');
  const pauseBtn=document.getElementById('pause');
  const stepBtn=document.getElementById('step');
  const speedEl=document.getElementById('speed');
  const resetBtn=document.getElementById('reset');
  const kernelEl=document.getElementById('kernel');

  function renderKernel(){
    kernelEl.innerHTML='';
    for(let r=0;r<K;r++){
      for(let c=0;c<K;c++){
        const d=document.createElement('div');
        d.className='kcell';
        d.textContent=KERNEL[r][c];
        kernelEl.appendChild(d);
      }
    }
  }

  function makeInput(){
    const a=[];
    for(let r=0;r<N;r++){
      const row=[];
      for(let c=0;c<N;c++){
        row.push(10+4*r+2*c);
      }
      a.push(row);
    }
    return a;
  }

  let input=makeInput();

  function renderInput(){
    boardEl.innerHTML='';
    for(let r=0;r<N;r++){
      for(let c=0;c<N;c++){
        const d=document.createElement('div');
        d.className='cell';
        d.textContent=input[r][c];
        boardEl.appendChild(d);
      }
    }
    const hl=document.createElement('div');
    hl.className='hl';
    hl.id='hl';
    boardEl.appendChild(hl);
  }

  function renderOutput(active){
    outEl.innerHTML='';
    for(let r=0;r<O;r++){
      for(let c=0;c<O;c++){
        const d=document.createElement('div');
        const isActive=active && active[0]===r && active[1]===c;
        d.className='ocell'+(isActive?' active':'');
        d.textContent=STATIC_OUTPUT[r][c];
        outEl.appendChild(d);
      }
    }
  }

  function moveHL(r,c){
    const cs=parseInt(getComputedStyle(document.documentElement).getPropertyValue('--cell'));
    const gp=parseInt(getComputedStyle(document.documentElement).getPropertyValue('--gap'));
    const left=c*(cs+gp);
    const top=r*(cs+gp);
    const hl=document.getElementById('hl');
    hl.style.width=`calc(var(--cell) * ${K} + var(--gap) * ${K-1})`;
    hl.style.height=`calc(var(--cell) * ${K} + var(--gap) * ${K-1})`;
    hl.style.left=left+'px';
    hl.style.top=top+'px';
  }

  const path=[];
  for(let r=0;r<O;r++){
    for(let c=0;c<O;c++) path.push([r,c]);
  }
  let idx=0; let playing=false; let timer=null;

  function step(){
    if(idx>=path.length){ stop(); return; }
    const [r,c]=path[idx];
    moveHL(r,c);
    renderOutput([r,c]);
    posEl.textContent=`(${r+1},${c+1})`;
    sumEl.textContent=STATIC_OUTPUT[r][c];
    idx++;
  }
  function play(){
    if(playing) return; playing=true; playBtn.disabled=true; pauseBtn.disabled=false;
    const go=()=>{ step(); if(playing && idx<path.length){ timer=setTimeout(go, parseInt(speedEl.value,10)); } else { stop(); } };
    go();
  }
  function stop(){ playing=false; playBtn.disabled=false; pauseBtn.disabled=true; clearTimeout(timer); timer=null; }
  function reset(){ stop(); idx=0; renderOutput(); moveHL(0,0); posEl.textContent='(1,1)'; sumEl.textContent='—'; }

  playBtn.addEventListener('click',play);
  pauseBtn.addEventListener('click',stop);
  stepBtn.addEventListener('click',step);
  resetBtn.addEventListener('click',reset);

  renderInput();
  renderOutput();
  renderKernel();
  moveHL(0,0);
});
</script>
</div>
</div>
<p>[add section on RNN]</p>
</section>
<section id="data-preprocessing-of-neural-networks-models" class="level3">
<h3 class="anchored" data-anchor-id="data-preprocessing-of-neural-networks-models">Data Preprocessing of Neural Networks models</h3>
<p>To prepare the data for CNN and RNN, we constructed an array with 3 dimensions which include the number of samples, the time window length and the number features. Each training sample is created by sliding a fixed window across the data. Within the array, the columns represent individual time steps, and the depth represent the features of the data. Since our prediction is one day ahead, each training example represents the observations within the window, for the next day prediction. Furthermore, the data was standardized to ensure the algorithms were not distorted by the different scales of the features. Lastly, the data was also one hot encoded, such that each categorical variable is split into multiple binary variable demarcating each category.</p>
<p>To preserve the temporal trends of the data, for the CNN and RNN the train and test split was not randomly shuffled. Instead, the first 80% of avalanche records were used as training examples, and the remaining became the test set.</p>
</section>
</section>
<section id="convolutional-neural-network" class="level2">
<h2 class="anchored" data-anchor-id="convolutional-neural-network">Convolutional Neural Network</h2>
<p>The selection of the convolution neural network and recurrent neural netowrk parameters involved two stages. Firstly, several candidate data sets were created with various time windows. In our cases, we tested a window of 3 days, 7 days, 30 days and 120 days. We kept the search parameters more narrow in this stage, and estimated many models in order to assess what prediction window would be most appropriate, according to validation accuracy. To estimate validation accuracy we used cross validation with 20% holdout set. All models were trained for 60 epochs save for the Feed forward Neural Network.</p>
<p>In the second stage, a more broad grid search was conducted on the chosen window, and the best model was chosen according to the highest validation accuracy. In all our tests presented for the CNN, we assessed architectures with two convolutional layers using the Relu function in those latent layers, and the softmax function in our input layer to create the class predictions. More complex architectures did not perform better, or meaningfully better.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="DS4i_writeup_files/figure-html/cnn_window_vis-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Considering Figure ? above, we decided on a prediction window of 7 days. Overall, out of the models tested, most perform best with a window of roughly 3 to 7 days, while 30 days and 120 days were shown to be meaningfully worse than former two options. Overall, validation accuracy between 3 to 7 days was competitive. However, 7 days appeared to be more robust, as the set of models with a 3 day prediction contained performances that achieved a much lower accuracy at the extreme end. <br> <br></p>
<div class="cell">
<div class="cell-output-display">
<table class="table table-hover caption-top table-sm table-striped small" data-quarto-postprocess="true">
<caption>Expanded Grid Search</caption>
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">hyperparameter</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">values</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">filters1</td>
<td style="text-align: left;">16, 32, 64</td>
</tr>
<tr class="even">
<td style="text-align: left;">filters2</td>
<td style="text-align: left;">16, 32, 64</td>
</tr>
<tr class="odd">
<td style="text-align: left;">kernel_sz</td>
<td style="text-align: left;">5, 15</td>
</tr>
<tr class="even">
<td style="text-align: left;">drop1</td>
<td style="text-align: left;">0.5, 0.7</td>
</tr>
<tr class="odd">
<td style="text-align: left;">drop2</td>
<td style="text-align: left;">0.5, 0.7</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="DS4i_writeup_files/figure-html/final_cnn_search_viz-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>After completing the above search, an expanded search with the hyperamaters presented in table ? was completed.The validation accuracy of the top 30 models is presented in Figure ? above. The Best performance overall was a validation accuracy of roughly 69%. We stuck with this model, as validation accuracy had not improved meaningfully over the course of the expanded search. The best performing model during the prediction window search acheived a validation accuracy of 67. The final selected model involved 32 filters in the first layer, followed by a dropout of 70%, then 16 layers in the second layers, followed by dropout of 70% and global average pooling into the the final output layer. <br> <br></p>
</section>
<section id="reccurrent-neural-network" class="level2">
<h2 class="anchored" data-anchor-id="reccurrent-neural-network">Reccurrent Neural Network</h2>
<p>The approach for the Reccurent Neural Network was the same as the CNN discussed above. Firstly a search over numerous candidate wndow sizes was completed, and a subsequent expanded search was done as well. In Figure ? below, the validation accuracy of the models test is presented. We used a combination of two Long Short-Term memory layers (LSTM), with dropout and varied the LSTM units and dropout values in the grid search.</p>
<p><br> <br></p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="DS4i_writeup_files/figure-html/RNN_window_search-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The window search for the recurrent neural network involved more competitive performances. In this case, a window of 30 days appears more robust overall, containing fewer worse performing models towards the extreme end. We therefore, conducted an exapnded grid search using that window, the results of which are presented in Figure ? below. The hypermarameters of for grid search is presented in the below table. <br> <br></p>
<div class="cell">
<div class="cell-output-display">
<table class="table table-hover caption-top table-sm table-striped small" data-quarto-postprocess="true">
<caption>RNN: grid search parameters</caption>
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">Hyperparameter</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Values</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">units1</td>
<td style="text-align: left;">16, 32, 64</td>
</tr>
<tr class="even">
<td style="text-align: left;">units2</td>
<td style="text-align: left;">16, 32, 64</td>
</tr>
<tr class="odd">
<td style="text-align: left;">drop1</td>
<td style="text-align: left;">0.3, 0.5, 0.7</td>
</tr>
<tr class="even">
<td style="text-align: left;">drop2</td>
<td style="text-align: left;">0.3, 0.5, 0.7</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="DS4i_writeup_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Out of the more expanded grid search, the best performing model achieved a validation accuracy of roughly 64%. We fitted this model to the full training data and used that to predict onto the test set. Overall, we were satisfied with this search as the validation accuracy had not improved drastically compared to the search across various windows done above. For example, the best performing model in the first stage of search achieved an accuracy of roughly 60%.</p>
</section>
<section id="modelling" class="level2">
<h2 class="anchored" data-anchor-id="modelling">Modelling</h2>
<p>Feed Forward Neural network</p>
<p>A feed-forward multilayer perceptron (MLP) neural network was developed for multi-class classification using the H2O deep learning framework. The objective was to predict a five level categorical outcome based on a high-dimensional feature set.</p>
<p>The MLP architecture was systematically optimized through a randomized discrete grid search to identify the most effective combination of hyperparameters. All candidate models were structured with a consistent input and output layer, while the hidden layer configuration was varied. The Input Layer Comprised 61 nodes, corresponding to the full set of hot one encoded engineered predictor variables, plus the bias. <br> <br></p>
<p>The grid search explored architectures containing between two and four hidden layers. Neuron configurations tested included dense layers such as [256, 128, 64], [512, 256, 128], and [128, 64]. The RectifierWithDropout activation function was initially considered to promote non-linearity and mitigate overfitting. The output layerContained five neurons, and employed a softmax activation function to generate a probability distribution over the classes.</p>
<p><br> <br></p>
<p>To counteract the effects of an imbalanced class distribution in the training data, a class-balancing strategy was implemented. Each training observation was assigned a weight inversely proportional to its class frequency, thereby increasing the influence of minority classes during the optimization of the loss function.</p>
<p><br> <br></p>
<p>The randomized grid search evaluated a maximum of 216 candidate models, exploring a predefined hyperparameter space. Key hyperparameters and their search ranges are detailed in Table ? below.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>       Hyperparameter                                   Values
1              hidden (128,128); (128,64); (64,32,16); (64,32)
2          activation                     RectifierWithDropout
3                  l1                            0, 1e-4, 1e-5
4                  l2                            0, 1e-4, 1e-5
5                rate                              0.01, 0.001
6 input_dropout_ratio                            0.1, 0.3, 0.5</code></pre>
</div>
<div class="cell-output-display">
<table class="table table-hover caption-top table-sm table-striped small" data-quarto-postprocess="true">
<caption>Feed Forward Neural Network Grid Search Hyperparameters</caption>
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">Hyperparameter</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Values</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">hidden</td>
<td style="text-align: left;">(128,128); (128,64); (64,32,16); (64,32)</td>
</tr>
<tr class="even">
<td style="text-align: left;">activation</td>
<td style="text-align: left;">RectifierWithDropout</td>
</tr>
<tr class="odd">
<td style="text-align: left;">l1</td>
<td style="text-align: left;">0, 1e-4, 1e-5</td>
</tr>
<tr class="even">
<td style="text-align: left;">l2</td>
<td style="text-align: left;">0, 1e-4, 1e-5</td>
</tr>
<tr class="odd">
<td style="text-align: left;">rate</td>
<td style="text-align: left;">0.01, 0.001</td>
</tr>
<tr class="even">
<td style="text-align: left;">input_dropout_ratio</td>
<td style="text-align: left;">0.1, 0.3, 0.5</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output-display">
<table class="table table-hover table-condensed caption-top table-sm table-striped small" data-quarto-postprocess="true">
<caption>Hyperparameter Grid</caption>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th" style="text-align: left; color: white !important;">Hyperparameter</th>
<th data-quarto-table-cell-role="th" style="text-align: left; color: white !important;">Values</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left; width: 22%; font-weight: bold;">hidden</td>
<td style="text-align: left; width: 60%; font-family: monospace;">(128,128)<br>
(128,64)<br>
(64,32,16)<br>
(64,32)</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 22%; font-weight: bold;">activation</td>
<td style="text-align: left; width: 60%; font-family: monospace;">RectifierWithDropout</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 22%; font-weight: bold;">l1</td>
<td style="text-align: left; width: 60%; font-family: monospace;">0, 1e-4, 1e-5</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 22%; font-weight: bold;">l2</td>
<td style="text-align: left; width: 60%; font-family: monospace;">0, 1e-4, 1e-5</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 22%; font-weight: bold;">rate</td>
<td style="text-align: left; width: 60%; font-family: monospace;">0.01, 0.001</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 22%; font-weight: bold;">input_dropout_ratio</td>
<td style="text-align: left; width: 60%; font-family: monospace;">0.1, 0.3, 0.5</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Each model was trained for a maximum of 200 epochs. An early stopping mechanism was employed to prevent overfitting, which terminated training if the validation set logloss did not improve by a tolerance of at least 1e-4 over 10 consecutive scoring intervals.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="DS4i_writeup_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5463852</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.680919</code></pre>
</div>
</div>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<section id="confusion-matrices" class="level3">
<h3 class="anchored" data-anchor-id="confusion-matrices">Confusion Matrices</h3>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>   [1] Moderate       Moderate       Considerable - Moderate      
   [5] Moderate       Moderate       Moderate       Low           
   [9] Low            Low            Low            Low           
  [13] Low            Low            Low            Low           
  [17] Low            Low            Low            Low           
  [21] Low            Low            Low            Considerable -
  [25] Moderate       Moderate       Considerable - Moderate      
  [29] Moderate       Moderate       Low            Low           
  [33] Low            Low            Moderate       Moderate      
  [37] Low            Low            Low            Moderate      
  [41] Moderate       Moderate       Moderate       Moderate      
  [45] Moderate       Moderate       Moderate       Considerable -
  [49] Considerable - Moderate       Moderate       Moderate      
  [53] Moderate       Moderate       Moderate       Low           
  [57] Moderate       Considerable - Moderate       Moderate      
  [61] Moderate       Moderate       Moderate       Moderate      
  [65] Moderate       Considerable - Moderate       Moderate      
  [69] Moderate       Moderate       Moderate       Moderate      
  [73] Low            Low            Low            Moderate      
  [77] Moderate       Moderate       Considerable - Moderate      
  [81] Moderate       Moderate       Moderate       Moderate      
  [85] Moderate       Moderate       Moderate       Moderate      
  [89] Moderate       Moderate       Moderate       Low           
  [93] Low            Low            Low            Low           
  [97] Low            Low            Moderate       Low           
 [101] Low            Low            Low            Low           
 [105] Low            Low            Low            Low           
 [109] Low            Moderate       Moderate       Moderate      
 [113] Moderate       Considerable - Low            Moderate      
 [117] Moderate       Moderate       Moderate       Moderate      
 [121] Moderate       Moderate       Moderate       Moderate      
 [125] Considerable - Considerable - Moderate       Moderate      
 [129] Moderate       Considerable - Moderate       Moderate      
 [133] Considerable - Considerable - Moderate       Moderate      
 [137] Moderate       Moderate       Moderate       Moderate      
 [141] Moderate       Moderate       Moderate       Moderate      
 [145] Moderate       Moderate       Moderate       Moderate      
 [149] Considerable - Moderate       Considerable - Considerable -
 [153] Moderate       Moderate       Considerable - Considerable -
 [157] Moderate       Considerable - Considerable - Considerable -
 [161] Considerable - Considerable - Considerable - Considerable -
 [165] Considerable - Considerable - Moderate       Considerable -
 [169] Considerable - Moderate       Considerable - Considerable -
 [173] Considerable - Considerable - Considerable - Considerable -
 [177] Considerable - Considerable - Considerable - Considerable -
 [181] Moderate       Moderate       Moderate       Considerable -
 [185] Moderate       Moderate       Moderate       Moderate      
 [189] Moderate       Moderate       Moderate       Moderate      
 [193] Low            Moderate       Low            Low           
 [197] Low            Low            Low            Low           
 [201] Low            Low            Low            Low           
 [205] Low            Low            Low            Low           
 [209] Low            Low            Low            Low           
 [213] Low            Low            Low            Low           
 [217] Low            Low            Low            Low           
 [221] Low            Low            Low            Low           
 [225] Low            Low            Low            Low           
 [229] Low            Low            Low            Low           
 [233] Low            Low            Low            Low           
 [237] Low            Low            Low            Low           
 [241] Low            Moderate       Considerable - Considerable -
 [245] Moderate       Moderate       Low            Moderate      
 [249] Low            Low            Low            Low           
 [253] Low            Low            Low            Low           
 [257] Low            Low            Low            Low           
 [261] Low            Low            Low            Low           
 [265] Low            Low            Low            Low           
 [269] Low            Low            Low            Low           
 [273] Low            Low            Low            Low           
 [277] Low            Low            Low            Low           
 [281] Low            Low            Low            Low           
 [285] Considerable - Moderate       Moderate       Moderate      
 [289] Low            Moderate       Low            Low           
 [293] Low            Low            Low            Low           
 [297] Low            Low            Low            Low           
 [301] Low            Low            Low            Low           
 [305] Low            Low            Low            Low           
 [309] Low            Low            Low            Low           
 [313] Low            Low            Low            Low           
 [317] Low            Low            Low            Low           
 [321] Low            Low            Low            Low           
 [325] Low            Low            Low            Low           
 [329] Moderate       Moderate       Moderate       Moderate      
 [333] Moderate       Moderate       Low            Moderate      
 [337] Low            Low            Low            Low           
 [341] Low            Low            Low            Low           
 [345] Low            Low            Low            Low           
 [349] Low            Low            Low            Low           
 [353] Low            Moderate       Moderate       Moderate      
 [357] Low            Moderate       Moderate       Moderate      
 [361] Low            Low            Low            Low           
 [365] Low            Low            Low            Low           
 [369] Low            Low            Low            Low           
 [373] Low            Low            Low            Low           
 [377] Low            Low            Low            Low           
 [381] Low            Low            Low            Low           
 [385] Low            Low            Low            Low           
 [389] Low            Low            Low            Low           
 [393] Low            Low            Low            Low           
 [397] Low            Low            Low            Low           
 [401] Low            Low            Low            Low           
 [405] Low            Moderate       Moderate       Low           
 [409] Low            Moderate       Moderate       Moderate      
 [413] Considerable - Considerable - Low            Moderate      
 [417] Considerable - Moderate       Moderate       Moderate      
 [421] Moderate       Moderate       Moderate       Moderate      
 [425] Moderate       Moderate       Moderate       Moderate      
 [429] Moderate       Moderate       Moderate       Moderate      
 [433] Moderate       Moderate       Moderate       Moderate      
 [437] Moderate       Moderate       Moderate       Moderate      
 [441] Moderate       Moderate       Moderate       Moderate      
 [445] Moderate       Moderate       Moderate       Moderate      
 [449] Moderate       Moderate       Moderate       Considerable -
 [453] Considerable - Moderate       Moderate       Moderate      
 [457] Moderate       Moderate       Moderate       Moderate      
 [461] Moderate       Moderate       Moderate       Moderate      
 [465] Considerable - Considerable - Considerable - Moderate      
 [469] Moderate       Moderate       Low            Low           
 [473] Low            Low            Low            Low           
 [477] Low            Low            Low            Low           
 [481] Low            Low            Low            Low           
 [485] Low            Low            Low            Low           
 [489] Low            Low            Low            Low           
 [493] Low            Low            Low            Low           
 [497] Low            Low            Low            Low           
 [501] Low            Low            Moderate       Moderate      
 [505] Moderate       Moderate       Moderate       Moderate      
 [509] Moderate       Moderate       Low            Low           
 [513] Low            Low            Low            Low           
 [517] Low            Low            Low            Low           
 [521] Low            Moderate       Moderate       Low           
 [525] Low            Moderate       Moderate       Moderate      
 [529] Moderate       Moderate       Moderate       Moderate      
 [533] Low            Low            Low            Low           
 [537] Low            Low            Low            Low           
 [541] Low            Low            Low            Low           
 [545] Low            Low            Low            Low           
 [549] Low            Low            Low            Low           
 [553] Low            Low            Low            Low           
 [557] Low            Low            Low            Low           
 [561] Low            Low            Low            Low           
 [565] Low            Low            Low            Low           
 [569] Low            Low            Low            Low           
 [573] Low            Low            Low            Low           
 [577] Low            Low            Low            Low           
 [581] Low            Low            Low            Low           
 [585] Low            Low            Low            Low           
 [589] Low            Low            Low            Moderate      
 [593] Moderate       Moderate       Moderate       Moderate      
 [597] Moderate       Moderate       Considerable - Considerable -
 [601] Considerable - Moderate       Moderate       Moderate      
 [605] Moderate       Moderate       Moderate       Moderate      
 [609] Moderate       Moderate       Moderate       Moderate      
 [613] Moderate       Moderate       Moderate       Moderate      
 [617] Low            Low            Low            Low           
 [621] Low            Low            Low            Low           
 [625] Low            Low            Low            Low           
 [629] Low            Low            Low            Low           
 [633] Low            Low            Low            Low           
 [637] Low            Low            Low            Low           
 [641] Low            Low            Low            Low           
 [645] Low            Low            Low            Moderate      
 [649] Considerable - Moderate       Considerable - Moderate      
 [653] Moderate       Moderate       Moderate       Moderate      
 [657] Moderate       Moderate       Moderate       Moderate      
 [661] Low            Moderate       Moderate       Moderate      
 [665] Moderate       Moderate       Moderate       Moderate      
 [669] Moderate       Moderate       Moderate       Low           
 [673] Low            Low            Low            Low           
 [677] Moderate       Moderate       Moderate       Moderate      
 [681] Moderate       Moderate       Moderate       Moderate      
 [685] Moderate       Moderate       Moderate       Moderate      
 [689] Low            Low            Low            Low           
 [693] Low            Low            Low            Low           
 [697] Low            Low            Low            Low           
 [701] Low            Low            Low            Low           
 [705] Low            Low            Low            Low           
 [709] Low            Low            Low            Low           
 [713] Low            Low            Low            Low           
 [717] Low            Low            Low            Low           
 [721] Low            Low            Low            Low           
 [725] Low            Low            Low            Low           
 [729] Low            Low            Low            Low           
 [733] Low            Low            Low            Low           
 [737] Low            Low            Low            Low           
 [741] Low            Low            Low            Moderate      
 [745] Moderate       Moderate       Moderate       Moderate      
 [749] Moderate       Moderate       Moderate       Moderate      
 [753] Considerable - Considerable - Considerable - Considerable -
 [757] Considerable - Considerable - Considerable - Considerable -
 [761] Moderate       Moderate       Considerable - Considerable -
 [765] Considerable - Moderate       Moderate       Moderate      
 [769] Considerable - Moderate       Moderate       Moderate      
 [773] Moderate       Moderate       Moderate       Moderate      
 [777] Moderate       Moderate       Low            Low           
 [781] Moderate       Moderate       Moderate       Moderate      
 [785] Moderate       Moderate       Moderate       Moderate      
 [789] Moderate       Moderate       Moderate       Moderate      
 [793] Moderate       Moderate       Moderate       Moderate      
 [797] Low            Low            Low            Low           
 [801] Low            Low            Low            Low           
 [805] Moderate       Moderate       Moderate       Moderate      
 [809] Moderate       Low            Low            Low           
 [813] Low            Low            Low            Low           
 [817] Low            Low            Low            Low           
 [821] Low            Low            Low            Low           
 [825] Low            Low            Low            Low           
 [829] Low            Low            Low            Low           
 [833] Low            Low            Low            Low           
 [837] Low            Low            Low            Low           
 [841] Low            Low            Low            Low           
 [845] Low            Low            Low            Low           
 [849] Low            Low            Low            Low           
 [853] Low            Low            Low            Low           
 [857] Low            Low            Low            Low           
 [861] Low            Low            Low            Low           
 [865] Low            Low            Low            Low           
 [869] Low            Moderate       Moderate       Moderate      
 [873] Moderate       Moderate       Moderate       Moderate      
 [877] Moderate       Moderate       Moderate       Moderate      
 [881] Moderate       Moderate       Moderate       Moderate      
 [885] Moderate       Moderate       Moderate       Moderate      
 [889] Moderate       Moderate       Considerable - Considerable -
 [893] Moderate       Moderate       Moderate       Moderate      
 [897] Moderate       Moderate       Moderate       Moderate      
 [901] Moderate       Moderate       Moderate       Low           
 [905] Low            Low            Low            Low           
 [909] Low            Low            Low            Low           
 [913] Low            Low            Low            Low           
 [917] Low            Low            Low            Low           
 [921] Low            Low            Low            Low           
 [925] Low            Low            Low            Low           
 [929] Low            Low            Low            Low           
 [933] Low            Low            Low            Low           
 [937] Low            Low            Low            Low           
 [941] Low            Low            Low            Low           
 [945] Low            Moderate       Moderate       Moderate      
 [949] Moderate       Low            Moderate       Moderate      
 [953] Moderate       Low            Moderate       Low           
 [957] Low            Low            Low            Low           
 [961] Moderate       Moderate       Low            Moderate      
 [965] Moderate       Moderate       Moderate       Moderate      
 [969] Moderate       Moderate       Moderate       Moderate      
 [973] Moderate       Moderate       Moderate       Low           
 [977] Low            Low            Moderate       Moderate      
 [981] Moderate       Low            Low            Moderate      
 [985] Low            Low            Low            Low           
 [989] Moderate       Moderate       Moderate       Moderate      
 [993] Moderate       Moderate       Moderate       Moderate      
 [997] Moderate       Moderate       Moderate       Moderate      
[1001] Moderate       Moderate       Moderate       Moderate      
[1005] Moderate       Moderate       Moderate       Moderate      
[1009] Moderate       Low            Low            Low           
[1013] Low            Low            Low            Low           
[1017] Low            Low            Low            Low           
[1021] Low            Low            Low            Low           
[1025] Low            Low            Low            Low           
[1029] Low            Low            Low            Low           
[1033] Low            Low            Low            Low           
[1037] Low            Low            Low            Low           
[1041] Low            Low            Low            Low           
[1045] Low            Low            Low            Low           
[1049] Low            Low            Low            Low           
[1053] Low            Low            Low            Low           
[1057] Low            Low            Low            Low           
[1061] Low            Low            Low            Low           
[1065] Low            Low            Low            Low           
[1069] Low            Low            Low            Low           
[1073] Low            Low            Low            Low           
[1077] Low            Low            Low            Low           
[1081] Low            Low            Low            Low           
[1085] Low            Low            Low            Low           
[1089] Low            Low            Moderate       Moderate      
[1093] Considerable - Moderate       Moderate       Moderate      
[1097] Moderate       Moderate       Moderate       Moderate      
[1101] Moderate       Moderate       Moderate       Moderate      
[1105] Moderate       Moderate       Low            Moderate      
[1109] Moderate       Moderate       Low            Moderate      
[1113] Moderate       Moderate       Moderate       Moderate      
[1117] Moderate       Moderate       Low            Moderate      
[1121] Moderate       Moderate       Moderate       Low           
[1125] Low            Low            Low            Low           
[1129] Low            Low            Low            Low           
[1133] Low            Low            Low            Low           
[1137] Low            Low            Low            Low           
[1141] Low            Low            Low            Low           
[1145] Low            Low            Low            Low           
[1149] Low            Low            Low            Low           
[1153] Low            Low            Low            Low           
[1157] Low            Low            Low            Moderate      
[1161] Low            Low            Moderate       Moderate      
[1165] Moderate       Moderate       Moderate       Moderate      
[1169] Moderate       Low            Low            Low           
[1173] Low            Low            Low            Low           
[1177] Low            Low            Low            Low           
[1181] Moderate       Moderate       Low            Moderate      
[1185] Low            Low            Low            Low           
[1189] Low            Low            Low            Low           
[1193] Low            Low            Low            Low           
[1197] Low            Low            Low            Low           
[1201] Low            Low            Low            Low           
[1205] Low            Low            Low            Low           
[1209] Low            Low            Low            Low           
[1213] Low            Low            Low            Low           
[1217] Low            Low            Low            Low           
[1221] Low            Low            Low            Low           
[1225] Low            Low            Low            Low           
[1229] Low            Low            Low            Low           
[1233] Low            Low            Moderate       Moderate      
[1237] Moderate       Moderate       Low            Low           
[1241] Moderate       Low            Low            Low           
[1245] Low            Low            Low            Low           
[1249] Low            Low            Low            Low           
[1253] Low            Low            Low            Low           
[1257] Low            Low            Low            Low           
[1261] Low            Low            Low            Low           
[1265] Low            Low            Low            Low           
[1269] Low            Low            Low            Low           
[1273] Low            Low            Low            Low           
[1277] Moderate       Moderate       Moderate       Moderate      
[1281] Moderate       Moderate       Moderate       Low           
[1285] Low            Low            Low            Low           
[1289] Low            Low            Low            Low           
[1293] Moderate       Moderate       Moderate       Moderate      
[1297] Moderate       Moderate       Low            Moderate      
[1301] Moderate       Moderate       Moderate       Moderate      
[1305] Moderate       Moderate       Moderate       Moderate      
[1309] Moderate       Moderate       Moderate       Low           
[1313] Low            Low            Moderate       Low           
[1317] Low            Low            Low            Low           
[1321] Low            Low            Low            Low           
[1325] Low            Low            Low            Low           
[1329] Low            Low            Low            Low           
[1333] Low            Low            Low            Low           
[1337] Low            Low            Low            Moderate      
[1341] Moderate       Moderate       Moderate       Moderate      
[1345] Moderate       Moderate       Moderate       Moderate      
[1349] Moderate       Moderate       Moderate       Moderate      
[1353] Moderate       Moderate       Moderate       Moderate      
[1357] Moderate       Moderate       Moderate       Moderate      
[1361] Moderate       Moderate       Moderate       Moderate      
[1365] Moderate       Moderate       Moderate       Low           
[1369] Moderate       Moderate       Moderate       Low           
[1373] Low            Low            Low            Low           
[1377] Low            Low            Low            Low           
[1381] Low            Low            Low            Low           
[1385] Low            Low            Low            Low           
[1389] Low            Low            Low            Low           
[1393] Low            Low            Low            Low           
[1397] Low            Low            Low            Moderate      
[1401] Moderate       Moderate       Low            Low           
[1405] Low            Low            Low            Low           
[1409] Low            Low            Low            Low           
[1413] Low            Low            Low            Low           
[1417] Low            Low            Low            Low           
[1421] Low            Low            Low            Low           
[1425] Low            Low            Low            Low           
[1429] Low            Low            Low            Low           
[1433] Low            Low            Low            Low           
[1437] Low            Low            Low            Low           
[1441] Low            Low            Low            Low           
[1445] Low            Low            Low            Low           
[1449] Moderate       Low            Low            Low           
[1453] Low            Low            Low            Low           
[1457] Low            Low            Low            Low           
[1461] Low            Low            Moderate       Moderate      
[1465] Moderate       Moderate       Moderate       Moderate      
[1469] Moderate       Low            Low            Moderate      
[1473] Moderate       Moderate       Moderate       Low           
[1477] Low            Moderate       Low            Low           
[1481] Low            Low            Low            Low           
[1485] Low            Low            Low            Low           
[1489] Low            Low            Low            Low           
[1493] Low            Low            Low            Moderate      
[1497] Moderate       Low            Low            Low           
[1501] Low            Low            Low            Low           
[1505] Low            Low            Low            Low           
[1509] Low            Low            Low            Low           
[1513] Low            Low            Low            Low           
[1517] Low            Low            Low            Low           
[1521] Low            Low            Low            Low           
[1525] Low            Low            Low            Low           
[1529] Low            Low            Low            Low           
[1533] Low            Low            Low            Low           
[1537] Low            Low            Low            Low           
[1541] Low            Low            Low            Low           
[1545] Low            Low            Low            Low           
[1549] Low            Low            Low            Low           
[1553] Low            Low            Low            Low           
[1557] Low            Low            Low            Low           
[1561] Low            Low            Low            Low           
[1565] Low            Low            Low           
Levels: Considerable - Considerable + High Low Moderate</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>   [1] High           High           High           Low           
   [5] Low            Low            Low            Low           
   [9] Low            Low            Low            Low           
  [13] Low            Low            Low            Low           
  [17] Low            Low            Low            Moderate      
  [21] Moderate       Moderate       Moderate       Moderate      
  [25] Moderate       Moderate       Moderate       Low           
  [29] Low            Low            Low            Low           
  [33] Low            Low            Low            Low           
  [37] Low            Low            High           High          
  [41] High           High           High           High          
  [45] High           High           High           High          
  [49] High           High           High           High          
  [53] High           High           High           High          
  [57] High           High           Low            Low           
  [61] Low            High           High           High          
  [65] High           High           High           High          
  [69] High           High           High           High          
  [73] High           High           High           Low           
  [77] Low            Low            Moderate       High          
  [81] High           High           High           Low           
  [85] Low            Low            Low            Low           
  [89] Low            Low            Low            Low           
  [93] Low            Low            Low            Low           
  [97] Low            Low            Low            Low           
 [101] Low            Low            Low            Low           
 [105] Low            Low            Low            Low           
 [109] Low            Low            Low            Low           
 [113] Low            Low            Low            Low           
 [117] Low            Low            Low            Low           
 [121] Low            Low            Low            Low           
 [125] Low            Low            Low            Low           
 [129] Low            Low            Low            Low           
 [133] Low            Low            Low            Low           
 [137] Low            Low            Low            Low           
 [141] Low            Low            Low            Moderate      
 [145] Moderate       Moderate       Moderate       Moderate      
 [149] Moderate       Moderate       Moderate       Moderate      
 [153] Moderate       Moderate       Moderate       Moderate      
 [157] Moderate       Moderate       Moderate       Moderate      
 [161] Moderate       Moderate       Moderate       Moderate      
 [165] Moderate       Moderate       Moderate       Moderate      
 [169] Moderate       Moderate       Moderate       Moderate      
 [173] Moderate       Moderate       Moderate       Moderate      
 [177] High           High           High           High          
 [181] High           High           High           High          
 [185] High           High           High           High          
 [189] Low            Low            Low            Low           
 [193] Low            Low            Low            Low           
 [197] Low            Low            Low            Low           
 [201] Low            Low            Low            Low           
 [205] Low            Low            Low            Low           
 [209] Low            Low            Low            Low           
 [213] Low            Low            Low            Low           
 [217] Low            Low            Low            Low           
 [221] Low            Low            Low            Low           
 [225] Low            Low            Low            Low           
 [229] Low            Low            Low            Low           
 [233] Low            Low            Low            Low           
 [237] Low            Low            Low            Low           
 [241] Low            Low            Low            Low           
 [245] High           Low            Low            Low           
 [249] Low            Low            Low            Low           
 [253] Low            Low            Low            Low           
 [257] Low            Low            Low            Low           
 [261] Low            Low            Low            Low           
 [265] Low            Low            Low            Low           
 [269] Low            Low            Low            Low           
 [273] Low            Low            Low            Low           
 [277] Low            Low            Low            Low           
 [281] Low            Low            Low            Low           
 [285] Low            Low            Low            Low           
 [289] Low            Low            Low            Low           
 [293] Low            Low            Low            Low           
 [297] Low            Low            Low            Low           
 [301] Low            Low            Low            Low           
 [305] Low            Low            Low            Low           
 [309] Low            Low            Low            Low           
 [313] Low            Low            Low            Low           
 [317] Low            Low            Low            Low           
 [321] Low            Low            Low            Low           
 [325] Low            Low            Low            Low           
 [329] Low            Low            Low            Low           
 [333] Low            Low            Low            Low           
 [337] Low            Low            Low            Low           
 [341] Low            Low            Low            Low           
 [345] Low            Low            Low            Low           
 [349] Low            Low            Low            Low           
 [353] Low            Low            Low            Low           
 [357] Low            Low            Low            Low           
 [361] Low            Low            Low            Low           
 [365] Low            Low            Low            Low           
 [369] Moderate       Moderate       Moderate       Low           
 [373] Low            Low            Low            Low           
 [377] Low            Low            Low            Low           
 [381] Low            Low            Low            Low           
 [385] Low            Low            Low            Low           
 [389] Low            Low            Low            Low           
 [393] Low            Low            Low            Moderate      
 [397] Moderate       Moderate       Moderate       Moderate      
 [401] Moderate       Moderate       Moderate       Moderate      
 [405] Moderate       Moderate       Moderate       Moderate      
 [409] Moderate       Moderate       Moderate       Moderate      
 [413] Moderate       Moderate       Moderate       Moderate      
 [417] Moderate       Moderate       Moderate       High          
 [421] High           High           High           High          
 [425] High           High           High           High          
 [429] High           High           High           High          
 [433] High           High           High           High          
 [437] High           High           High           High          
 [441] High           High           High           High          
 [445] High           High           High           Low           
 [449] Low            Low            Low            Low           
 [453] High           High           High           High          
 [457] High           Moderate       Moderate       Moderate      
 [461] High           High           High           High          
 [465] High           High           Considerable - Low           
 [469] Low            Low            Low            Low           
 [473] Low            Low            Low            Low           
 [477] Low            Low            Low            Low           
 [481] Low            Low            Low            Low           
 [485] Low            Low            Low            Low           
 [489] Low            Low            Low            Low           
 [493] Low            Low            Low            Considerable -
 [497] Low            Low            Low            Low           
 [501] Low            Low            Low            Low           
 [505] Low            Low            Low            Low           
 [509] Low            Low            Low            Low           
 [513] Low            Low            Low            Low           
 [517] Low            Low            Low            Moderate      
 [521] Moderate       Moderate       Moderate       Moderate      
 [525] Moderate       Moderate       Low            Low           
 [529] Low            Low            Low            Low           
 [533] Low            Low            Low            Low           
 [537] Low            Low            Low            Low           
 [541] Low            Low            Low            Low           
 [545] Low            Low            Low            Low           
 [549] Low            Low            Low            Low           
 [553] Low            Low            Low            Low           
 [557] Low            Low            Low            Low           
 [561] Low            Low            Low            Low           
 [565] Low            Low            Low            Low           
 [569] Low            Low            Low            Low           
 [573] Low            Low            Low            Low           
 [577] Low            Low            Low            Low           
 [581] Low            Low            Low            Low           
 [585] Low            Low            Low            Low           
 [589] Low            Low            Low            Low           
 [593] Low            Low            Low            Low           
 [597] Low            Low            Low            Low           
 [601] Moderate       Low            Moderate       Moderate      
 [605] Moderate       Moderate       Moderate       Moderate      
 [609] Moderate       Moderate       Moderate       Moderate      
 [613] High           High           Moderate       Moderate      
 [617] Moderate       Moderate       Low            Low           
 [621] Low            Low            Low            Low           
 [625] Low            Low            Low            Low           
 [629] Low            Low            Low            Low           
 [633] Low            Low            Low            Low           
 [637] Low            Low            Low            Low           
 [641] Low            High           High           High          
 [645] High           High           High           High          
 [649] High           High           High           High          
 [653] High           High           High           High          
 [657] High           High           High           High          
 [661] High           High           High           High          
 [665] High           High           High           High          
 [669] High           High           High           High          
 [673] High           High           Low            Low           
 [677] Low            Low            Low            Low           
 [681] Low            Low            Low            Low           
 [685] Low            Low            Low            Low           
 [689] Low            Low            Low            Low           
 [693] Low            Low            Low            Low           
 [697] Low            Low            Low            Low           
 [701] Low            Low            Low            Low           
 [705] Low            Low            Low            Low           
 [709] Low            Low            Low            Low           
 [713] High           High           Low            Low           
 [717] Low            Low            Low            Low           
 [721] Low            Low            Low            Low           
 [725] Low            Low            Low            Low           
 [729] Low            Low            Low            Low           
 [733] Low            Low            Low            Low           
 [737] Low            Low            Low            Moderate      
 [741] Moderate       Moderate       High           High          
 [745] High           High           High           High          
 [749] High           High           High           High          
 [753] High           High           High           High          
 [757] High           High           High           High          
 [761] High           High           High           High          
 [765] High           High           High           High          
 [769] High           High           High           Considerable -
 [773] Low            Low            Low            Low           
 [777] Low            Low            Low            Low           
 [781] Low            Low            Low            Low           
 [785] Low            Low            Low            Low           
 [789] Low            Low            Low            Low           
 [793] Low            Low            Low            Low           
 [797] Low            Low            Low            Low           
 [801] Low            Low            Low            Low           
 [805] Low            Low            Low            Low           
 [809] Low            Low            Low            Low           
 [813] Low            Low            Low            Low           
 [817] Low            Low            Low            Low           
 [821] Low            Low            Low            Low           
 [825] Low            Low            Low            Low           
 [829] Low            Low            Low            Low           
 [833] Low            Low            Low            Low           
 [837] Low            Low            Low            Low           
 [841] Low            Low            Low            Low           
 [845] Low            Low            Low            Low           
 [849] Low            Low            Low            Low           
 [853] Low            Low            High           High          
 [857] High           High           High           High          
 [861] High           High           Moderate       Moderate      
 [865] Moderate       Moderate       Moderate       Moderate      
 [869] High           High           High           High          
 [873] High           High           High           High          
 [877] High           High           High           High          
 [881] High           High           High           High          
 [885] High           High           High           High          
 [889] High           High           High           High          
 [893] High           High           High           High          
 [897] High           High           Low            Low           
 [901] Low            Low            Low            Low           
 [905] Low            Low            Low            Low           
 [909] Low            Low            Low            Low           
 [913] Low            Low            Low            Low           
 [917] Low            Low            Low            Low           
 [921] Low            Low            Low            Low           
 [925] Low            Low            Low            Low           
 [929] Low            Low            Low            Low           
 [933] Low            Low            Low            Low           
 [937] Low            Low            Low            Low           
 [941] Low            High           High           High          
 [945] High           High           High           High          
 [949] High           High           High           High          
 [953] High           High           High           High          
 [957] High           High           High           High          
 [961] High           High           High           High          
 [965] High           High           Low            Low           
 [969] Low            Low            Low            Low           
 [973] Low            Low            Low            Low           
 [977] Low            Low            Low            Low           
 [981] Low            High           High           High          
 [985] High           High           High           High          
 [989] High           Moderate       Moderate       Moderate      
 [993] Moderate       Moderate       Moderate       Moderate      
 [997] High           High           High           High          
[1001] High           High           High           High          
[1005] High           Low            Low            Low           
[1009] Low            Low            Low            Low           
[1013] Low            Low            Low            Low           
[1017] Low            Low            Low            Low           
[1021] Low            Low            Low            Low           
[1025] Low            Low            Low            Moderate      
[1029] Moderate       Moderate       Moderate       Moderate      
[1033] Moderate       Moderate       Moderate       Low           
[1037] Low            Low            Moderate       Low           
[1041] Low            Low            Low            Low           
[1045] Low            Low            Low            Low           
[1049] Low            Low            Low            Low           
[1053] Low            Low            Low            Low           
[1057] Low            Low            Low            Low           
[1061] Low            Low            Low            Low           
[1065] Low            Low            Low            Low           
[1069] Low            Low            Low            Low           
[1073] Low            Low            Low            Low           
[1077] Low            Low            Low            Low           
[1081] Low            Low            Low            Low           
[1085] Low            Low            Low            Low           
[1089] Low            Low            Low            Low           
[1093] Low            Low            Low            Low           
[1097] High           High           High           Considerable -
[1101] Considerable - High           High           High          
[1105] High           High           High           High          
[1109] High           High           High           High          
[1113] Moderate       Moderate       Moderate       Moderate      
[1117] Moderate       Moderate       Moderate       Moderate      
[1121] Moderate       Moderate       High           Low           
[1125] Low            Low            Low            Low           
[1129] Low            Low            Low            Low           
[1133] Low            Low            Low            Low           
[1137] Low            Low            Low            Low           
[1141] Low            Low            Low            Low           
[1145] Low            Low            Low            Low           
[1149] Low            Low            Low            Low           
[1153] Low            Low            Considerable + Considerable +
[1157] Considerable + Considerable + Considerable + Considerable +
[1161] Considerable + Considerable + Considerable + Considerable +
[1165] Moderate       Considerable + Considerable + Considerable -
[1169] Low            Low            Low            Low           
[1173] Low            Low            Low            Low           
[1177] Low            Low            Low            Low           
[1181] Low            Low            Low            Low           
[1185] Low            Low            Low            Low           
[1189] Low            Low            Low            Low           
[1193] Low            Low            Low            Low           
[1197] Low            Low            Low            Low           
[1201] Low            Low            Low            Low           
[1205] Low            Low            Low            Low           
[1209] Low            Low            Low            Low           
[1213] Low            Low            Low            Low           
[1217] Low            Low            Low            Low           
[1221] Low            Low            Low            Low           
[1225] Low            Low            Low            Low           
[1229] Low            Low            Low            Low           
[1233] Low            Low            Low            Low           
[1237] Low            Low            Low            Low           
[1241] Low            Low            Low            Low           
[1245] Low            Low            Low            Low           
[1249] Low            Low            Low            Low           
[1253] Low            Low            Low            Low           
[1257] Low            Low            Low            Low           
[1261] Low            Low            Low            Low           
[1265] Low            Low            Moderate       Moderate      
[1269] Moderate       Moderate       Moderate       Moderate      
[1273] Moderate       Moderate       Moderate       Moderate      
[1277] Moderate       Moderate       High           High          
[1281] High           High           High           High          
[1285] High           High           High           High          
[1289] High           High           High           High          
[1293] High           Considerable - High           High          
[1297] High           High           High           High          
[1301] High           High           High           High          
[1305] High           High           High           High          
[1309] High           High           High           High          
[1313] High           High           High           High          
[1317] High           High           High           High          
[1321] High           High           Low            Low           
[1325] Low            Low            Low            Low           
[1329] Low            Low            Low            Low           
[1333] Low            Low            Low            Low           
[1337] Low            Low            Low            Low           
[1341] Low            Low            Low            Low           
[1345] Low            Low            Low            Low           
[1349] Low            Low            Low            Low           
[1353] Low            Low            Low            Low           
[1357] Low            Low            Low            Low           
[1361] Low            Low            Low            Low           
[1365] Low            Low            Low            Low           
[1369] Low            Low            Low            Low           
[1373] Low            Low            Low            Low           
[1377] Low            Low            Low            Low           
[1381] Low            Low            Low            Low           
[1385] Low            Low            Low            Low           
[1389] Low            Low            Low            Low           
[1393] Low            Low            Low            Low           
[1397] Low            Low            Low            Low           
[1401] Low            Low            Low            Low           
[1405] Low            Low            Low            Low           
[1409] Low            Low            Low            Low           
[1413] Low            Low            Low            Low           
[1417] Low            Low            Low            Low           
[1421] Low            Low            Low            Low           
[1425] Low            Low            Low            Low           
[1429] Low            Low            Low            Low           
[1433] Low            Low            Low            Low           
[1437] Low            Low            Low            Low           
[1441] Low            Low            Low            High          
[1445] High           High           High           High          
[1449] Low            Low            Low            Low           
[1453] Low            Low            High           High          
[1457] Moderate       Moderate       Moderate       Moderate      
[1461] Moderate       Moderate       Moderate       Moderate      
[1465] Moderate       Moderate       Moderate       High          
[1469] Moderate       Moderate       Moderate       Moderate      
[1473] Low            Low            Low            Low           
[1477] Low            Low            Low            Low           
[1481] Low            Low            Low            Low           
[1485] Low            Low            Low            Low           
[1489] Low            Low            Low            Low           
[1493] Low            Low            Low            Low           
[1497] Low            Low            Low            Low           
[1501] Low            Low            Low            Low           
[1505] Low            Low            Low            Low           
[1509] Low            Low            Low            Low           
[1513] Low            Low            Low            Low           
[1517] Low            Low            Low            Low           
[1521] Low            Low            Low            Low           
[1525] Low            Low            Low            Low           
[1529] Low            Low            Low            Low           
[1533] Low            Low            Low            Low           
[1537] Low            Low            Low            Low           
[1541] Low            Low            Low            Low           
[1545] Low            Low            Low            Low           
[1549] Low            Low            Low            Low           
[1553] Low            Low            Low            Low           
[1557] Low            Low            Low            Low           
[1561] Low            Low            Low           
Levels: Considerable - Considerable + High Low Moderate</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "factor"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "factor"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1567</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1563</code></pre>
</div>
</div>
<p><a href="#fig-compare_cms" class="quarto-xref">Figure&nbsp;1</a> displays the confusion matrices for our 3 models. Our FFNN has a clearer diagonal, which is indicative of its stronger performance. The confusion matrix for the RNN is very diffused with widespread misclassifications. <a href="#tbl-accuracy_comparison" class="quarto-xref">Table&nbsp;1</a> confirms this observation is indeed the case, as the RNN had the lowest accuracy (34.6%) and the FFNN had the highest (75.4%).</p>
<p>The FFNN had some noticeable misclassifications between Considerable- and Moderate. We see that for 103 cases, the model predicted Considerable- instead of Moderate, which shows that it confuses those two classes a lot. Similarly, 112 Low cases were predicted as Moderate, another pair of classes the model struggles with.</p>
<p>[Talk about RNN]</p>
<p>In the case of the CNN, almost all predictions go to Low. There is a noticeable concentration on the off-diagonal for Low classifications (717), and a considerable concentration of Moderate classifications (213). The CNN collapsed into predicting these classes in many cases. Also, it completely fails to High or Considerable+. The rows for the respective classes are all zeros. This shows that this model fell for imbalance bias, favouring the majority class Low.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-compare_cms" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-compare_cms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="DS4i_writeup_files/figure-html/fig-compare_cms-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-compare_cms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Confusion Matrices Comparing the Final CNN, RNN, and Feed-Forward Models
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div id="tbl-accuracy_comparison" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-accuracy_comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Overall Accuracy by Model
</figcaption>
<div aria-describedby="tbl-accuracy_comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="table do-not-create-environment cell caption-top table-sm table-striped small" data-quarto-postprocess="true">
<caption>Overall Accuracy by Model</caption>
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">Model</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">FFNN</td>
<td style="text-align: left;">75.4%</td>
</tr>
<tr class="even">
<td style="text-align: left;">CNN</td>
<td style="text-align: left;">68.1%</td>
</tr>
<tr class="odd">
<td style="text-align: left;">RNN</td>
<td style="text-align: left;">54.6%</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
</section>
<section id="model-statistics-by-class" class="level3">
<h3 class="anchored" data-anchor-id="model-statistics-by-class">Model Statistics by Class</h3>
<p><a href="#tbl-ffn_stats_by_class" class="quarto-xref">Table&nbsp;2</a>, <a href="#tbl-cnn_stats_by_class" class="quarto-xref">Table&nbsp;3</a> and <a href="#tbl-rnn_stats_by_class" class="quarto-xref">Table&nbsp;4</a> summaries our model statistics by class for all 3 models.</p>
<div class="cell">
<div id="tbl-ffn_stats_by_class" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ffn_stats_by_class-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: FFNN Statistics by Class
</figcaption>
<div aria-describedby="tbl-ffn_stats_by_class-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="table do-not-create-environment cell caption-top table-sm table-striped small" data-quarto-postprocess="true">
<caption>FFNN Statistics by Class</caption>
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Sensitivity</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Specificity</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Pos Pred Value</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Neg Pred Value</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Precision</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Recall</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">F1</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Prevalence</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Detection Rate</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Detection Prevalence</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Balanced Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Class: Considerable -</td>
<td style="text-align: right;">0.7812500</td>
<td style="text-align: right;">0.8613782</td>
<td style="text-align: right;">0.5910165</td>
<td style="text-align: right;">0.9388646</td>
<td style="text-align: right;">0.5910165</td>
<td style="text-align: right;">0.7812500</td>
<td style="text-align: right;">0.6729475</td>
<td style="text-align: right;">0.2040816</td>
<td style="text-align: right;">0.1594388</td>
<td style="text-align: right;">0.2697704</td>
<td style="text-align: right;">0.8213141</td>
</tr>
<tr class="even">
<td style="text-align: left;">Class: Considerable +</td>
<td style="text-align: right;">0.1772152</td>
<td style="text-align: right;">0.9865682</td>
<td style="text-align: right;">0.4117647</td>
<td style="text-align: right;">0.9576271</td>
<td style="text-align: right;">0.4117647</td>
<td style="text-align: right;">0.1772152</td>
<td style="text-align: right;">0.2477876</td>
<td style="text-align: right;">0.0503827</td>
<td style="text-align: right;">0.0089286</td>
<td style="text-align: right;">0.0216837</td>
<td style="text-align: right;">0.5818917</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Class: High</td>
<td style="text-align: right;">0.5600000</td>
<td style="text-align: right;">0.9909268</td>
<td style="text-align: right;">0.5000000</td>
<td style="text-align: right;">0.9928571</td>
<td style="text-align: right;">0.5000000</td>
<td style="text-align: right;">0.5600000</td>
<td style="text-align: right;">0.5283019</td>
<td style="text-align: right;">0.0159439</td>
<td style="text-align: right;">0.0089286</td>
<td style="text-align: right;">0.0178571</td>
<td style="text-align: right;">0.7754634</td>
</tr>
<tr class="even">
<td style="text-align: left;">Class: Low</td>
<td style="text-align: right;">0.8208270</td>
<td style="text-align: right;">0.9792350</td>
<td style="text-align: right;">0.9657658</td>
<td style="text-align: right;">0.8845015</td>
<td style="text-align: right;">0.9657658</td>
<td style="text-align: right;">0.8208270</td>
<td style="text-align: right;">0.8874172</td>
<td style="text-align: right;">0.4164541</td>
<td style="text-align: right;">0.3418367</td>
<td style="text-align: right;">0.3539541</td>
<td style="text-align: right;">0.9000310</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Class: Moderate</td>
<td style="text-align: right;">0.7515275</td>
<td style="text-align: right;">0.8523677</td>
<td style="text-align: right;">0.6988636</td>
<td style="text-align: right;">0.8826923</td>
<td style="text-align: right;">0.6988636</td>
<td style="text-align: right;">0.7515275</td>
<td style="text-align: right;">0.7242395</td>
<td style="text-align: right;">0.3131378</td>
<td style="text-align: right;">0.2353316</td>
<td style="text-align: right;">0.3367347</td>
<td style="text-align: right;">0.8019476</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<div class="cell">
<div id="tbl-cnn_stats_by_class" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-cnn_stats_by_class-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3: CNN Statistics by Class
</figcaption>
<div aria-describedby="tbl-cnn_stats_by_class-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="table do-not-create-environment cell caption-top table-sm table-striped small" data-quarto-postprocess="true">
<caption>CNN Statistics by Class</caption>
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Sensitivity</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Specificity</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Pos Pred Value</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Neg Pred Value</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Precision</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Recall</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">F1</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Prevalence</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Detection Rate</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Detection Prevalence</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Balanced Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Class: Considerable -</td>
<td style="text-align: right;">0.2192982</td>
<td style="text-align: right;">0.9676531</td>
<td style="text-align: right;">0.3472222</td>
<td style="text-align: right;">0.9404682</td>
<td style="text-align: right;">0.3472222</td>
<td style="text-align: right;">0.2192982</td>
<td style="text-align: right;">0.2688172</td>
<td style="text-align: right;">0.0727505</td>
<td style="text-align: right;">0.0159541</td>
<td style="text-align: right;">0.0459477</td>
<td style="text-align: right;">0.5934757</td>
</tr>
<tr class="even">
<td style="text-align: left;">Class: Considerable +</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">1.0000000</td>
<td style="text-align: right;">NaN</td>
<td style="text-align: right;">0.9757498</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">0.0242502</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">0.5000000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Class: High</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">1.0000000</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">NA</td>
</tr>
<tr class="even">
<td style="text-align: left;">Class: Low</td>
<td style="text-align: right;">0.8273684</td>
<td style="text-align: right;">0.6564019</td>
<td style="text-align: right;">0.7875752</td>
<td style="text-align: right;">0.7117750</td>
<td style="text-align: right;">0.7875752</td>
<td style="text-align: right;">0.8273684</td>
<td style="text-align: right;">0.8069815</td>
<td style="text-align: right;">0.6062540</td>
<td style="text-align: right;">0.5015954</td>
<td style="text-align: right;">0.6368858</td>
<td style="text-align: right;">0.7418852</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Class: Moderate</td>
<td style="text-align: right;">0.5505376</td>
<td style="text-align: right;">0.7813067</td>
<td style="text-align: right;">0.5150905</td>
<td style="text-align: right;">0.8046729</td>
<td style="text-align: right;">0.5150905</td>
<td style="text-align: right;">0.5505376</td>
<td style="text-align: right;">0.5322245</td>
<td style="text-align: right;">0.2967454</td>
<td style="text-align: right;">0.1633695</td>
<td style="text-align: right;">0.3171666</td>
<td style="text-align: right;">0.6659222</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<div class="cell">
<div id="tbl-rnn_stats_by_class" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-rnn_stats_by_class-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4: RNN Statistics by Class
</figcaption>
<div aria-describedby="tbl-rnn_stats_by_class-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="table do-not-create-environment cell caption-top table-sm table-striped small" data-quarto-postprocess="true">
<caption>RNN Statistics by Class</caption>
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Sensitivity</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Specificity</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Pos Pred Value</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Neg Pred Value</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Precision</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Recall</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">F1</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Prevalence</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Detection Rate</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Detection Prevalence</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Balanced Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Class: Considerable -</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">0.9951724</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">0.9273779</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">NaN</td>
<td style="text-align: right;">0.0722969</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">0.0044786</td>
<td style="text-align: right;">0.4975862</td>
</tr>
<tr class="even">
<td style="text-align: left;">Class: Considerable +</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">0.9921363</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">0.9761444</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">NaN</td>
<td style="text-align: right;">0.0236724</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">0.0076775</td>
<td style="text-align: right;">0.4960682</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Class: High</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">0.8048624</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">0.0000000</td>
<td style="text-align: right;">0.1951376</td>
<td style="text-align: right;">NA</td>
</tr>
<tr class="even">
<td style="text-align: left;">Class: Low</td>
<td style="text-align: right;">0.8345627</td>
<td style="text-align: right;">0.5276873</td>
<td style="text-align: right;">0.7319778</td>
<td style="text-align: right;">0.6735967</td>
<td style="text-align: right;">0.7319778</td>
<td style="text-align: right;">0.8345627</td>
<td style="text-align: right;">0.7799114</td>
<td style="text-align: right;">0.6071657</td>
<td style="text-align: right;">0.5067179</td>
<td style="text-align: right;">0.6922585</td>
<td style="text-align: right;">0.6811250</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Class: Moderate</td>
<td style="text-align: right;">0.1336207</td>
<td style="text-align: right;">0.9135578</td>
<td style="text-align: right;">0.3949045</td>
<td style="text-align: right;">0.7140825</td>
<td style="text-align: right;">0.3949045</td>
<td style="text-align: right;">0.1336207</td>
<td style="text-align: right;">0.1996779</td>
<td style="text-align: right;">0.2968650</td>
<td style="text-align: right;">0.0396673</td>
<td style="text-align: right;">0.1004479</td>
<td style="text-align: right;">0.5235892</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<pre><code></code></pre>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>